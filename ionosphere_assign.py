# -*- coding: utf-8 -*-
"""Ionosphere Assign.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xmqLi-oJKI-KMY-5MtFXFlN0gQEBPZNE
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense 
from tensorflow.keras.optimizers import Adam, SGD

"""# **Data Loading**"""

data = pd.read_csv('/content/ionosphere_data.csv')

data.describe()

data.head()

# show the boolean dataframe             
print(" \nshow the boolean Dataframe : \n\n", data.isnull())  
# Count total NaN in a DataFrame 
print(" \nCount total NaN in a DataFrame : \n\n", 
       data.isnull().sum().sum())

print(data.shape)

data.info()

print(data.columns)

"""# **Splitting**"""

X=data.iloc[:,0:34]
y=data.iloc[:,-1]
data['label'] = data['label'].map({'g':1,'b':0})

data.head()

data.info()

X.head()

y.head()

# separate dataset into train and test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4, random_state=42)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

"""# **Feature Selection**"""

corrmat = data.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(25,25))
g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap="RdYlGn")

# with the following function we can select highly correlated features
# it will remove the first feature that is correlated with anything other feature

def correlation(dataset, threshold):
    col_corr = set()  # Set of all the names of correlated columns
    corr_matrix = dataset.corr()
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value
                colname = corr_matrix.columns[i]  # getting the name of column
                col_corr.add(colname)
    return col_corr

corr_features = correlation(X_train, 0.7)
len(set(corr_features))

corr_features

X_train = X_train.drop(corr_features,axis=1)
X_test= X_test.drop(corr_features,axis=1)

X_train

input_shape=(X_train.shape[1])
input_shape

"""# **Network Building and Training**"""

from tensorflow.keras import models
from tensorflow.keras import layers

def build_model():
    model = models.Sequential()
    model.add(layers.Dense(10, activation='relu',
                           input_shape=(X_train.shape[1],)))
    model.add(layers.Dense(8, activation='relu'))
    model.add(layers.Dense(6, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

model = build_model()
history=model.fit(X_train,y_train,validation_split=0.33,epochs=100,batch_size=16, verbose=0)

y_pred=model.predict(X_test)

from sklearn.metrics import roc_auc_score
roc_auc_score(y_test,y_pred)

"""# **Data Visualization**"""

# list all data in history
print(history.history.keys())

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='lower right')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

"""# **Evauation**"""

# Evaluation phase

# Use the testing set to evaluate the model
scores = model.evaluate(X_train,y_train)

# Print out the accuracy
print('\n')
print('Accuracy=', scores[1])

"""# **Prediction**"""

y_pred[:5].astype('int64')

y_test[:15]